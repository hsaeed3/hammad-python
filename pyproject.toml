[project]
name = "hammad"
version = "0.0.1"
description = "hammad - *Nightly* hyper-fast opinionated resources and modules built for quick development."
readme = "README.md"
requires-python = ">=3.11"
authors = [
    {name = "Hammad Saeed", email = "hammadaidev@gmail.com"},
]
dependencies = [
    "httpx>=0.28.1",
    "ollama>=0.5.1",
    "pydantic>=2.11.5",
    "rich>=14.0.0",
    "tavily-python>=0.7.5",
    "python-dotenv>=1.0.1",
    "pydantic-extra-types>=2.10.5",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project.optional-dependencies]
# Chat & LLM
chat = [
    "litellm>=1.72.4",
    "openai-agents>=0.0.17",
    "instructor>=0.4.0",
]
# Memory (If Paired with the Chat Dependency can Expose Memory as Tools
# for an Agent)
memory = [
    "memvid>=0.1.3",
    "sqlalchemy>=2.0.39",
]
# Used to enable launching agents / the agent service / memory as an API or as a 
# this creates a persistent running service, even once the window is closed; and retains
# the 'hammadpy' command namespace in your terminal (both windows, linux, macos) untill you
# run `hammadpy service uninstall`
# background service through `hammadpy service install` & `hammadpy service start`
service = [
    "fastapi>=0.115.8",
    "uvicorn>=0.34.0",
    "python-multipart>=0.0.19",
    "sse-starlette>=1.1.0",
]

[dependency-groups]
dev = [
    "ruff",
    "uv",
    "pytest",
    "twine>=6.1.0",
]
